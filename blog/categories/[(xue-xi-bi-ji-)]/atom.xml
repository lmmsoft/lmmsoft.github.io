<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 【学习笔记】 | My Octopress Blog]]></title>
  <link href="http://lmmsoft.github.io/blog/categories/[(xue-xi-bi-ji-)]/atom.xml" rel="self"/>
  <link href="http://lmmsoft.github.io/"/>
  <updated>2016-06-23T00:39:08+08:00</updated>
  <id>http://lmmsoft.github.io/</id>
  <author>
    <name><![CDATA[Your Name]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[【学习笔记】斯坦福大学>机器学习>1-机器学习的动机与应用]]></title>
    <link href="http://lmmsoft.github.io/blog/2013/01/31/1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%BA%94%E7%94%A8/"/>
    <updated>2013-01-31T00:00:00+08:00</updated>
    <id>http://lmmsoft.github.io/blog/2013/01/31/1-机器学习的动机与应用</id>
    <content type="html"><![CDATA[<p>今天开始学斯坦福大学的机器学习课程，争取看看能不能保证每天听一节</p>




<p>课程链接：http://v.163.com/special/opencourse/machinelearning.html
<pre># 1-机器学习的动机和应用
网址[http://v.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html]</pre></p>




<p>[0:00] 课程介绍，老师、助教介绍<br />
[2:00] 机器学习介绍<br />
[3:20] 小调查，50%学生来自CS，剩下各学科都有一些<br />
[5:10] 对机器学习的一点认识：个别得意东西很难写程序，学习型算法是可以的<br />
[9:45] 这门课的几个目标<br />
    1. 理解机器学习让人兴奋的地方<br />
    2. 学生将机器学习用在自己感兴趣的地方<br />
    3. 有能力开始机器学习的研究<br />
[10:35] 先修课程<br />
    1. 基本CS知识，数据结构，写代码<br />
    2. 基本概率统计知识<br />
    3. 基本线性代数<br />
[12:50] CS229是电视课程，课程信息、作业介绍<br />
[16:00] 建议大家组建学习小组<br />
[18:00] 作业不要作弊<br />
[19:40] 其中考试时间<br />
[20:00] course project,一个研究性项目，用在自己的领域或者选个问题用ML研究它，<br />
    目标是可发表的研究成果<br />
    往年同学的，放网站了一些项目<br />
    最多三人一组<br />
[23:45] MATLAB或OCTAVE 完成一些算法作业<br />
[26:40] 讨论课<br />
[28:15] QA<br />
[31:30] Machine Learning Definition<br />
    Field of study that gives computers the alility to learn without being explicitly </p>




<p>programmed.<br />
[36:00] 这门课有四个部分,并举例<br />
    1. supervised Learning：给算法提供了标准答案<br />
    2. Learning Theory:学习理论<br />
    3. [50:15] Unsupervised Learning:没有答案，在里面找一些结构;聚类算法，常用于社交网络研究<br />
    4. [62:25] Reinforcement强化学习：定义好的行为和坏的行为，然后用学习型算法<br />
[67:30] QA</p>




<p></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[【学习笔记】宾夕法尼亚州立大学>华尔街训练营>华尔街礼仪]]></title>
    <link href="http://lmmsoft.github.io/blog/2013/01/30/%E5%8D%8E%E5%B0%94%E8%A1%97%E7%A4%BC%E4%BB%AA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <updated>2013-01-30T00:00:00+08:00</updated>
    <id>http://lmmsoft.github.io/blog/2013/01/30/华尔街礼仪学习笔记</id>
    <content type="html"><![CDATA[<p><h1>宾夕法尼亚州立大学->华尔街训练营>华尔街礼仪</h1></p>




<p><a href="http://v.163.com/movie/2008/8/J/R/M7AQO97FT_M7B4R0VJR.html">视频地址</a></p>




<p>这是我听课时用markdown记下的笔记，基本上PPT上面的东西和一些口述的都记下了</p>




<p><h2>提纲</h2></p>




<p><ol>
<li>7 seconds to success</li>
<li>Conversation Basis</li>
<li>Munching 7 Mingling 
<!--more--></li>
</ol></p>




<p><h2>7 seconds to success</h2></p>




<p><h3>第一印象很重要，第一句话只有12words</h3></p>




<p><ul>
<li>自信</li>
</ul></p>




<p><h3>Rule of 12</h3></p>




<p><ol>
<li>1st 12 words shoud include "thank you"谢谢</li>
<li>1st 12 words shoud be those of confidence 要自信，要让人感觉像是潜力股</li>
<li>1st 12 inches from head down shuld be impeccably groomed 无可挑剔</li>
<li>1st 12 inches from floor up shuld be well-maintained 用心雕琢（不要化妆品，不要挂件，不要香水，涂上体香剂，鞋子擦亮，不要白袜子，男人应该尖头鞋子）</li>
</ol></p>




<p><h3>conveying confidence</h3></p>




<p><ol>
<li>Smile</li>
<li>Walk briskly,head held high</li>
<li>Sing your theme song</li>
<li>Believe in yourself</li>
<li>Visualize yourself in the position</li>
<li>Convey enthusiasm, interest, sense of energy</li>
<li>Be positive</li>
<li>Be able to laugh at yourself, Never Assume that because someone is better looking or higher level</li>
</ol></p>




<p><h3>First impression faux pas(失礼、失态)</h3></p>




<p><ol>
<li>giggling(矫揉造作)</li>
<li>Hand gestures</li>
<li>Touching(very personal)</li>
</ol></p>




<p><h2>Conversation Basis</h2></p>




<p><h3>Every conversion is an opportunity for success</h3></p>




<p><h3>You never know when someone is in a position to help you</h3></p>




<p><h3>Handshake</h3></p>




<p><ol>
<li>Open Hand</li>
<li>Firm grasp</li>
<li>Once up, once down</li>
<li>Convey warmth &amp; confidence</li>
<li>Make eye contact</li>
</ol></p>




<p><h3>Introductions</h3></p>




<p><h4>Where</h4></p>




<p><ol>
<li>Go where the people are</li>
<li>Best place - food table, bar</li>
<li>If no one introduces you, introduce yourself</li>
<li>Look for approachable people. People who are alone is a great place to start</li>
</ol></p>




<p><h4>How</h4></p>




<p><ul>
<li>Name tag on your right</li>
<li>4 Rules</li></ul></p>




<p><ol>
<li>Older people first</li>
<li>Women before men</li>
<li>Same age-some gender- no mateer</li>
<li>VIP(with tittle) 1st</li>
</ol>
<li>I'm Robin(drill) How are you?<br />
Thank your for..."</li>
<li>Stand if you are sitting</li>
<li>Repeat the other person's name often</li>
<li>Follow up the intro with a conversation starter "Bill and I went to Penn State together" 我和这次活的的主办人Bill是同一年进入宾州大学的</li>
</p>




<p><h4>what you do, who you are, where you're headed 可以谈的话题</h4></p>




<p><ol>
<li>background/skills</li>
<li>Current/past experiences eg:internship/student club/leader</li>
<li>Future objectives/goals</li>
</ol></p>




<p><h3>AWKWARD MOMENTS</h3></p>




<p><ul>
<li>Didn't understand the name</li></ul></p>




<p><ul>
<li>I'm sorry, I didn't understand yours name.</li>
<li>I'm want to make sure that your name is XXX?</li>
</ul>
<li>Forget name<br />
Step back &amp; say "Have your two met?"</li>
<li>Only remember one name<br />
Step back &amp; say "Have you met Bill?"</li>
</p>




<p><h3>The Name Game</h3></p>




<p><ul>
<li>Never give a person a nickname</li>
<li>shake hands and repeat the name, then use name as often as possible</li>
<li>Give others the gift of your name</li>
</ul></p>




<p><h3>Small Talk 寒暄</h3></p>




<p><ul>
<li>Take the risk of talking to someone new! Be the first to say hello~</li>
<li>Be sincere.Treat everyone like the most improtant person</li>
<li>Ask open question(answer was not "Yes/No")</li>
<li>Weather/Dinner</li>
<li>John去纽约之前带画了个大表，什么时候见什么人，是什么头衔，谈话主题</li>
</ul></p>




<p><h3>Small Talk RULES</h3></p>




<p><ul>
<li>Do convey a genuine(真实的) like of people</li>
<li>Do not talk about sex, politics or religion</li>
<li>Do be aware of events of the day</li>
<li>Do ask questions about the company</li>
<li>Do get people to talk about themselves</li>
<li>准备几个自己的精彩时刻30s</li>
</ul></p>




<p><h3>Listening is the Key to a Good Conversation</h3></p>




<p><ul>
<li>Listen actively</li>
<li>Keep your distance, 不要打断</li>
</ul></p>




<p><h3>BREAKING AWAY</h3></p>




<p><ul>
<li>Be polite</li>
<li>Excuse me , I must say hello to sb</li>
<li>"I enjoyed meeting you"</li>
<li>Move on if the other person seems bored</li>
<li>Move on to make room for others</li>
<li>Never leave someone standing alone</li>
<li>[this is gift and ability]</li>
</ul></p>




<p><h3>Turn offs忌讳</h3></p>




<p><ol>
<li>No touching hair,nose,eyes or other people</li>
<li>No hands in pockets or behind backs</li>
<li>Keep Hands above board it says your are confident/attentive</li>
<li>No touching others</li>
<li>Don't say :"How is your wife" "How's your work"</li>
</ol></p>




<p><h3>Combat mingling phobia</h3></p>




<p><ol>
<li>Decide an arrival/departure time</li>
<li>create an itinerary(路程)</li>
<li>admit that you know no one</li>
<li>Recongnize that everyone is as nervous as yourself</li>
<li>Give yourself a break</li>
<li>learn one new thing</li>
<li>Think of this as "a recruiter" NOT "the recruiter OR "a job NOT" the "job"</li>
<li>Don't be the last to leave</li>
<li>Have fun~</li>
</ol></p>




<p><h2>Munching 7 Mingling</h2></p>




<p><h3>Drinking</h3></p>




<p><ol>
<li>Play it safe</li>
<li>Wine glasses are held by the stem </li>
<li>Always drink beer from a glass</li>
<li>Napkin - olate -glass by stem-wipe</li>
<li>Ice cubes(冰块) are not an edible(可食用的) part of the beverage(饮料)</li>
</ol></p>




<p><h3>Eating</h3></p>




<p><ol>
<li>Eat first for best protection</li>
<li>Use a plate</li>
<li>No double dipping</li>
<li>Put sauces(沙拉酱) on the plate and dip into them</li>
<li>No cheese, no grease, no bones</li>
<li>No talking with food in your mouth</li>
<li>Remove anything inedible with your thumb and farefinger</li>
<li>Eat skowly, taking bites only large enough to chew comfortably and quietly</li>
</ol></p>




<p><h3>General RULES</h3></p>




<p><ol>
<li>Always say something nice about the food to the host</li>
<li>Excuse yourself to blow your nose</li>
<li>If you are rawe ,eat first mingle later</li>
<li>Cough and sneeze to the side with mouth covered by napkin</li>
</ol></p>




<p><h2>Robin's Top Tips[从视频的54min开始]</h2></p>




<p><ul>
<li>社交能给你带来更多的面试机会</li>
<li>翻翻校友录数据库</li>
<li>在金融中心，利用地理优势</li>
<li>暑假去看看朋友，找到说我想和你 吃个午餐，一起聊聊</li>
<li>暑期实习的时候，不仅和小圈子(饭团)一起吃饭，每周还要有一次，在食堂，随便找个座位坐下来，然后自我介绍：“hi, I'm new here, I'm just kind of learning about the place, what is it that you do?你具体是做哪方面的？”</li>
<li>人都在那里了，尽量用好公司的关系~</li>
<li>用好社交网络，知道自己想要什么，努力，在环境中接触不同的人</li>
<li>实习生问了一下，就和CEO一起吃饭咯</li>
<li>eg:一个实习生在健身房更衣室和CEO聊了一会儿，后来获得一个面试机会</li>
<li>参加一场酒会就是一次面试，不要放松警惕 </li>
</ul>
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《Item-to-Item Collaborative Filtering》笔记]]></title>
    <link href="http://lmmsoft.github.io/blog/2013/01/04/%E3%80%8Aitem-to-item-collaborative-filtering%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <updated>2013-01-04T00:00:00+08:00</updated>
    <id>http://lmmsoft.github.io/blog/2013/01/04/《item-to-item-collaborative-filtering》笔记</id>
    <content type="html"><![CDATA[<p>因毕设需要元旦翻译了amazon.com那篇著名的协同过滤的文章 <a href="http://academic.research.microsoft.com/Publication/861437/amazon-com-recommendations-item-to-item-collaborative-filtering">《Amazon.com Recommendations: Item-to-Item Collaborative Filtering 》</a></p>




<p><p>翻译之余顺便做了笔记，和csdn blog上的<a href="http://blog.csdn.net/poson/article/details/7644080">另一篇</a>对比了一下：<br />
* 我的差距：不少地方没有读透，只用了原文词语，没能抽象的概括出来，说明领域知识太少，还需要恶补<br />
* 好的地方：我的层次更加鲜明，可能是受思维导图影响吧
<!--more-->
下面是我的笔记</p></p>




<p><h1>亚马逊推荐系统，物品到物品的协同过滤</h1></p>




<p><h2>电子商务推荐算法的使用环境</h2></p>




<p><ul>
<li>大数据：有海量数据的大型零售商，以千万计顾客、百万计的登记在册的不同商品。</li>
<li>实时：许多应用要求结果实时返回，在半秒之内，还要产生高质量的推荐。</li>
<li>冷启动：新顾客一般信息有限，以少量购买或产品评级为基础。</li>
<li>老数据：较老的顾客信息丰沛，以大量的购买和评级为基础。</li>
<li>数据不稳定：每一次交互都可提供有价值的顾客数据，算法必须立即对新的信息做出响应。</li>
</ul></p>




<p><h2>解决推荐问题通常有三个途径</h2></p>




<p><ul>
<li>传统的协同过滤</li></ul></p>




<p><ul>
<li>人到人</li>
<li>物品到物品</li>
</ul>
<li>聚类模型</li>
<li>基于搜索的方法</li>
</p>




<p><h2>物品到物品推荐的特点</h2></p>




<p>与传统人到人协同过滤不同，物品到物品算法的在线计算规模与顾客数量和产品目录中的商品数量无关</p>




<p><ul>
<li>实时</li>
<li>适应海量</li>
<li>高质量</li>
</ul></p>




<p><h2>推荐算法</h2></p>




<p><ul>
<li>找相似顾客：传统协同过滤、聚类</li>
<li>找相似物品：搜索、物品到物品协同过滤</li>
</ul></p>




<p><h2>传统的协同过滤</h2></p>




<p><ul>
<li>顾客->商品的N维向量(N是商品数量，M是顾客数量)</li>
<li>正负分量作为评级</li>
<li>弥补热卖商品的影响->向量分量乘以逆频率（已购买顾客数量的倒数）->使不知名的商品更相关</li>
<li>向量非常稀疏</li>
<li>余弦相似度</li>
</ul></p>




<p><h3>传统算法复杂度</h3></p>




<p><ul>
<li>最坏O(MN)</li>
<li>因为稀疏，复杂度接近O(M + N)</li></ul></p>




<p><ul>
<li>扫描每一个顾客大约是O(M)，而不是O(MN)</li>
<li>少数高级顾客，需要O(N)</li>
</ul>
<li>总计算量很大</li>
</p>




<p><h3>传统算法优化</h3></p>




<p><ul>
<li>减小数据量</li></ul></p>




<p><ul>
<li>减小M</li></ul></p>




<p><ul>
<li>对顾客随机抽样</li>
<li>丢弃购买很少的顾客</li>
<li>缺点：用户相似度降低</li>
</ul>
<li>减小N</li></p>




<p><ul>
<li>丢弃极热门/极冷门商品</li>
<li>缺点：只购买过最热/最冷商品的顾客得不到推荐</li>
</ul>

<li>减少所需计算的商品数量</li></p>




<p><ul>
<li>商品空间区隔</li></ul></p>




<p><ul>
<li>通过一个小的常数因子，在产品类别或主题分类的基础上</li>
<li>缺点：把推荐限制在特定产品或主题领域之内</li>
</ul>

<li>降维(减小M和N)</li></p>




<p><ul>
<li>聚类</li>
<li>主分量分析</li>
<li>缺点：只购买过最热/最冷商品的顾客得不到推荐</li>
</ul>
</p>




<p><h2>聚类模型</h2></p>




<p><ul>
<li>对顾客基础进行细分，寻找与当前用户相似的顾客</li>
<li>分类：非监督学习算法</li>
<li>大数据的理想聚类不切实际，一般：贪心聚类（随机初始集等）</li>
<li>相似性计算</li>
<li>优点：可扩展性，在线性能好，复杂和昂贵的聚类计算会离线运行</li>
<li>缺点：粗粒度相似性差，细粒度计算量大</li>
</ul></p>




<p><h2>基于搜索的方法</h2></p>




<p><p>构造一个搜索查询，以寻找其他热卖的商品，通过同一作者、艺术家或导演，或利用相似的关键词或主题<br />
* 用户数据少的时候->性能和计算量不错<br />
* 用户数据多->只能使用子集->降低推荐质量<br />
* 综合推荐质量较差</p></p>




<p><h2>物品到物品的协同过滤</h2></p>




<p><ul>
<li>匹配到相似的商品</li></ul></p>




<p><p>For 每件商品 in 产品目录, I1<br />
    For 每位顾客 C in 购买过 I1 <br />
        For 每件商品 I2  由顾客 C 所购买的<br />
            记录一个顾客所购买的 I1 和 I2<br />
       For 每件商品 I2<br />
          在 I1 与 I2 之间计算相似度</p>
<li>离线计算极费时间</li></p>




<p><ul>
<li>最坏需要O(N^2*M)</li>
<li>实际运行中，接近O(NM)</li>
</ul>
<li>在线计算非常快</li></p>




<p><ul>
<li>仅仅取决于该用户购买或评级过商品的数量</li>
</ul>
</p>




<p><h3>可扩展性好</h3></p>




<p><ul>
<li>传统的协同过滤</li></ul></p>




<p><ul>
<li>离线计算少</li>
<li>线计算量大（取决于顾客和登记在册商品的数量）</li>
<li>维度降低、抽样或区隔方法会降低推荐品质。</li>
</ul>
<li>聚类模型</li></p>




<p><ul>
<li>离线运行大量的计算</li>
<li>推荐质量相对较差</li>
<li>出于改进，可以增加人群细分的数量，但细分人群计算量大</li>
</ul>
<li>基于搜索的模型</li></p>




<p><ul>
<li>离线建立关键词、范畴、作者索引</li>
<li>不能提供符合兴趣、定向内容的推荐</li>
<li>对于数据多的顾客扩展性不佳</li>
</ul>
<li>物品到物品协同过滤</li></p>




<p><ul>
<li>耗时巨大的相似商品表格是离线算</li>
<li>在线部分：计算量独立于商品目录的规模或顾客的总数</li>
<li>推荐质量更好</li>
<li>冷启动性能好</li>
</ul>

</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Talk Given by Prof. Heather Zheng: Network Design for Big-Data]]></title>
    <link href="http://lmmsoft.github.io/blog/2012/12/06/talk-given-by-prof-heather-zheng-network-design-for-big-data/"/>
    <updated>2012-12-06T00:00:00+08:00</updated>
    <id>http://lmmsoft.github.io/blog/2012/12/06/talk-given-by-prof-heather-zheng-network-design-for-big-data</id>
    <content type="html"><![CDATA[<p>MSRA平时的talk和seminars非常多，之前听了若干，但回来之后都没怎么整理，全废了T_T</p>




<p><p>以后争取每次都能整理下，加深印象。虽然我的笔记质量不高，只有自己能看懂~
<!--more--></p></p>




<p>————————————我是分割线——————————</p>




<p><p>Talk:         Network Design for Big-Data<br />
Speaker:     Prof. Heather Zheng, U. C. Santa Barbara.<br />
Time:         11:00AM, December 6, Thursday<br />
Venue:    Demo Room (14366, 14F)<br />
讲座两个部分，第一部分是用flexible wireless进行data center通信建设；第二部分是scalable social network analysis 社交网络计算。</p></p>




<p><h1>Part1.Network Design for Big-Data</h1></p>




<p><h2>traffic hotspots</h2></p>




<p><ol>
<li>unpredictable</li>
<li>double fee</li>
</ol></p>




<p><h2>Wireless links-flexible</h2></p>




<p><h2>challenge #1 Link Blockage</h2></p>




<p>3D Beamforming，这里有个图：</p>




<p><ol>
<li>用天花板Reflector进行反射</li>
<li>接收器下面用Absorberx吸收信号，防止再反射</li>
</ol></p>




<p><h2>challenge #2 Interference Footprint</h2></p>




<p><h2>challenge #3 Robustness ti Alignment Error</h2></p>




<p>concurrency</p>




<p><h2>总结：</h2></p>




<p>因为我不懂无线传感网络方面的知识，所以这个talk的细节不是太懂，不过用天花板反射倒是理解了，很巧妙的思路~</p>




<p>————————————我是分割线——————————</p>




<p><h1>Part2.enable scalable graph processing for today’s massive online social networks</h1></p>




<p><h2>distance ranked social</h2></p>




<p>rank search result based on social distance</p>




<p><h2>Key Limition Today:Scale</h2></p>




<p><h2>A drastically different alternative</h2></p>




<p><ol>
<li>O(1) query time</li>
<li>Parallelize</li>
</ol></p>




<p>Graph embedding</p>




<p><h1>Approach for Embedding</h1></p>




<p><h3>require:</h3></p>




<p><ol>
<li>BFS</li>
<li>converge quickly</li>
<li>optimize accuracy</li>
</ol></p>




<p><h1>shortest path search</h1></p>




<p><p>说了一个算法，说得太快，没听清T_T<br />
Rigel 12倍于 Sketch Tree</p></p>




<p><h2>总结</h2></p>




<p><p>具体算法没听懂，但我知道了这个东西：<br />
1. 社交网络对人名的搜索可以借助预处理来给出一个很好的结果，比尔搜索Bob，可以找到你可能认识的Bob，而人人网找人搜索很烂，几乎不能按好友数排序。<br />
1. 社交网络计算量很大，有很多算法值得探究~<br />
1. 做社交网络不容易，人人的研发能力不足以提供完美的服务</p></p>




<p>————————————我是分割线——————————</p>




<p><h1>附：</h1></p>




<p>Abstract:</p>




<p><p>The arrival of big-data applications has created significant challenges to network design.  For example, batched data processing jobs are straining network capacity in data center networks, causing unexpected outages and service downtimes, while social network companies struggle to manage millions of users and billions of user events and queries in real time. In both cases, network architects must find new, novel ways to support traffic/service demands that display complex structure and vary significantly with time.<br />
In this talk, I will discuss two of our recent works on big-data.</p></p>




<p><ol>
<li>First, I will talk about challenges in dealing with dynamic traffic hotspots in data centers, and our solution using flexible wireless interconnects to augment wired connections. We propose 3D beamforming 60GHz links that leverage ceiling reflection to overcome key challenges in deploying wireless links, creating parallel wireless links connecting any racks at wired data rates.</li>
<li>Next, I will discuss our effort to enable scalable graph processing for today’s massive online social networks. We propose graph coordinate systems, a new approach that accurately approximates node distances in constant time by embedding graphs into coordinate spaces. Our design not only provides accurate results for massive graphs (43 million nodes), but also is naturally parallelizable across computer clusters. It answers node-distance queries in 10’s of microsecond, and produces shortest path results up to 18 times faster than prior solutions with similar accuracy.</li>
<li>Finally, I will conclude with a brief summary of other ongoing projects.</li>
</ol></p>




<p>Bio:</p>




<p>Haitao (Heather) Zheng is currently an Associate Professor at the Computer Science department, U. C. Santa Barbara. She completed her M.S. and Ph.D. degrees in Electrical and Computer Engineering at Univ. of Maryland, College Park (1998, 1999) and her B. S. degree from Xi’an Jiaotong University (gifted class). She is a recipient of the MIT Technology Review’s TR-35 Award (Young Innovators Under 35) and the World Technology Network Fellow Award. Her work has been covered by media outlets such as New York Times, Boston Globe, MIT Technology Review, and Computer World. Her work on cognitive radios was named as the top-10 Emerging Technologies by MIT Technology Review in 2006.  Her research spans areas of wireless networking, distributed systems, economics, data-intensive computing, and social networks.
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对话图灵奖获得者John Hopcroft]]></title>
    <link href="http://lmmsoft.github.io/blog/2012/10/24/%E5%AF%B9%E8%AF%9D%E5%9B%BE%E7%81%B5%E5%A5%96%E8%8E%B7%E5%BE%97%E8%80%85johnhopcroft/"/>
    <updated>2012-10-24T00:00:00+08:00</updated>
    <id>http://lmmsoft.github.io/blog/2012/10/24/对话图灵奖获得者johnhopcroft</id>
    <content type="html"><![CDATA[<p><pre>The Turing Award Winner John Hopcroft will visit MSRA on Oct.24th 2012.
It is honored to attend the presentation he gave to the undergraduate interns.</pre></p>




<p>The topic covered in the presentation:<br />
- John share his personal experience<br />
- For a senior undergraduate student, how to make right choice in the right time<br />
- The comments for current undergraduate and graduate education<br />
- Suggestions to students about how to develop their core skills to meet the future needs</p>




<p>整个对话大概持续1个小时，John先说了20min,然后就话题讨论和QA,结束之后和交大ACM班的同学圆桌，我就没法参与了。</p>




<p>全过程里我记了大概两页笔记，摘录精华如下：<br />
1. <strong>关于选择：</strong> You only one life to live , so do the job you really love doing, don't concentrate on your payment<br />
2. <strong>关于热爱：</strong> If you do what you love to do, you'll work 16h a day, if you don't you will only work 8 hours<br />
3. <strong>关于兴趣</strong>： 多选几门课，找到自己的兴趣点<br />
4. <strong>关于传道授业：</strong> Every Thusday afternoon, I provide free food for my students and talk about their research problems（ps:我现在的mentor这点上很像，每周请实习生吃一次饭，大家带着问题来）<br />
5. <strong>关于道路：</strong> If your mentor bring you to the machine learning, data mining... you are on the good way</p>




<p>还有对MSRA的实习生项目的优劣进行了探讨，比较了中国和美国大学的不同，并对学习给出了一些建议。</p>




<p>ps:<br />
the bio of John<br />
John Hopcroft<br />
John Edward Hopcroft (born October 7, 1939) is an American theoretical computer scientist. His textbooks on theory of computation (also known as the Cinderella book) and data structures are regarded as standards in their fields. He is the IBM Professor of Engineering and Applied Mathematics in Computer Science at Cornell University.</p>




<p>He received his master's degree and Ph.D. from Stanford University in 1962 and 1964, respectively. He worked for three years at Princeton University and since then has been based at Cornell University.</p>




<p>In addition to his research work, he is well known for his books on algorithms and formal languages coauthored with Jeffrey Ullman and Alfred Aho, regarded as classic texts in the field.</p>




<p>He received the Turing Award – the most prestigious award in 1986. The citation states that he received the award "for fundamental achievements in the design and analysis of algorithms and data structures." Along with his work with Tarjan on planar graphs he is also known for the Hopcroft–Karp algorithm for finding matchings in bipartite graphs. In 1994 he was inducted as a Fellow of the Association for Computing Machinery. In 2005 he received the Harry H. Goode Memorial Award "for fundamental contributions to the study of algorithms and their applications in information processing." In 2008 he received the Karl V. Karlstrom Outstanding Educator Award "for his vision of and impact on computer science, including co-authoring field-defining texts on theory and algorithms, which continue to influence students 40 years later, advising PhD students who themselves are now contributing greatly to computer science, and providing influential leadership in computer science research and education at the national and international level."</p>




<p>In 1992 John Hopcroft was nominated to the National Science Board by George H.W. Bush.<br />
In 2009, he received an honorary doctorate from Saint Petersburg State University of Information Technologies, Mechanics and Optics.</p>




<p>Hopcroft is also the co-recipient (with Jeffrey Ullman) of the 2010 IEEE John von Neumann Medal, “For laying the foundations for the fields of automata and language theory and many seminal contributions to theoretical computer science.”</p>

]]></content>
  </entry>
  
</feed>
