#!/usr/bin/env python3
"""
ç”Ÿæˆé…ç½®ï¼ˆå›ºå®šå‚æ•°ï¼Œä¸æä¾› CLI é€‰é¡¹ï¼‰:
- è¾“å…¥ç›®å½•: _posts/, _drafts/ï¼ˆå…¼å®¹ _post/, _draft/ï¼‰
- æ”¯æŒæ‰©å±•å: .md/.markdown/.html
- è¾“å‡ºæ–‡ä»¶: CONTENT_INDEX.mdï¼ˆä»“åº“æ ¹ç›®å½•ï¼‰
- è¡¨å¤´: æ—¥æœŸ | æ ‡é¢˜ | æ˜¯å¦å‘å¸ƒ | ç±»å‹(post/draft) | æœ‰å›¾ç‰‡ | æ ¼å¼ | ç›¸å¯¹è·¯å¾„ | å¤‡æ³¨
- æ’åº: æ—¥æœŸé™åºï¼›æŒ‰å¹´ä»½åˆ†ç»„ï¼Œå¹´ä»½é™åºï¼Œå¹¶å±•ç¤ºæ¯å¹´ å‘å¸ƒ/å¾…å‘å¸ƒ/è‰ç¨¿ æ•°é‡
"""
from __future__ import annotations

import datetime as dt
import os
import re
import sys
from dataclasses import dataclass
from typing import Dict, Iterable, List, Optional, Tuple, Union
from urllib.parse import quote


ROOT_DIR = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
OUTPUT_FILE = os.path.join(ROOT_DIR, "CONTENT_INDEX.md")
SEARCH_DIRS = ["_posts", "_drafts", "_post", "_draft"]  # åä¸¤ä¸ªç”¨äºå…¼å®¹å®¹é”™
_YAML_FALLBACK_WARNED = False
SITE_BASE = "https://lmmsoft.github.io"
ALLOWED_EXTS = (".md", ".markdown", ".html")


IMAGE_PATTERNS = [
    re.compile(r"!\[[^\]]*?\]\((?P<src>[^)]+)\)", re.DOTALL),
    re.compile(r'<img[^>]*?src=["\'](?P<src>[^"\']+)["\'][^>]*?>', re.IGNORECASE),
]


@dataclass
class Record:
    path: str
    rel_path: str
    date: dt.datetime
    year: int
    title: str
    published: bool
    content_type: str  # post/draft
    image_label: str  # â–/ğŸ–¼ï¸/ğŸŒ/ğŸ”€/â“
    remark: str = ""
    permalink_url: Optional[str] = None
    fmt: str = ""


def list_markdown_files() -> List[str]:
    candidates: List[str] = []
    for rel_dir in SEARCH_DIRS:
        abs_dir = os.path.join(ROOT_DIR, rel_dir)
        for root, _, files in os.walk(abs_dir):
            for name in files:
                lower = name.lower()
                if lower.endswith(ALLOWED_EXTS):
                    candidates.append(os.path.join(root, name))
    return candidates


def split_front_matter(content: str) -> Tuple[Dict, str]:
    """è¿”å› front matter å­—å…¸ä¸æ­£æ–‡ï¼ˆè‹¥æœªæ‰¾åˆ°ï¼Œfront matter ä¸ºç©ºï¼‰ã€‚"""
    match = re.match(r"\A---\s*\n(.*?)\n---\s*\n", content, re.DOTALL)
    if not match:
        return {}, content
    yaml_block = match.group(1)
    body = content[match.end() :]
    data = parse_front_matter_yaml(yaml_block)
    return data if isinstance(data, dict) else {}, body


def parse_front_matter_yaml(yaml_block: str) -> Dict:
    """ä¼˜å…ˆä½¿ç”¨ PyYAMLï¼›ç¼ºå¤±æˆ–è§£æå¤±è´¥åˆ™é™çº§ä¸ºç®€æ˜“è¡Œçº§è§£æã€‚"""
    try:
        import yaml  # type: ignore

        return yaml.safe_load(yaml_block) or {}
    except ModuleNotFoundError:
        return parse_yaml_fallback(yaml_block, reason="PyYAML æœªå®‰è£…")
    except Exception as exc:  # pragma: no cover - å®¹é”™
        print(f"[WARN] front matter YAML è§£æå¤±è´¥: {exc}", file=sys.stderr)
        return parse_yaml_fallback(yaml_block, reason="YAML è§£æå¤±è´¥")


def parse_yaml_fallback(text: str, *, reason: str) -> Dict[str, Union[str, bool]]:
    """ç®€æ˜“è§£æï¼šä»…å¤„ç† key: value/true/falseï¼›å¤æ‚ç»“æ„éœ€ä¾èµ– PyYAMLã€‚"""
    meta: Dict[str, Union[str, bool]] = {}
    for raw_line in text.splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#") or ":" not in line:
            continue
        key, value = line.split(":", 1)
        meta[key.strip()] = coerce_simple_value(value.strip())
    global _YAML_FALLBACK_WARNED
    if meta and not _YAML_FALLBACK_WARNED:
        print(
            f"[INFO] front matter ä½¿ç”¨ç®€æ˜“è§£æï¼ˆåŸå› : {reason}ï¼›å¤æ‚ç»“æ„å¯èƒ½æ— æ³•è¿˜åŸå®Œæ•´ front matterï¼‰",
            file=sys.stderr,
        )
        _YAML_FALLBACK_WARNED = True
    return meta


def coerce_simple_value(text: str) -> Union[str, bool]:
    stripped = text.strip()
    if (stripped.startswith('"') and stripped.endswith('"')) or (
        stripped.startswith("'") and stripped.endswith("'")
    ):
        stripped = stripped[1:-1].strip()
    lowered = stripped.lower()
    if lowered in {"true", "false"}:
        return lowered == "true"
    return stripped


def parse_date(value: object) -> Optional[dt.datetime]:
    if value is None:
        return None
    if isinstance(value, dt.datetime):
        return value
    if isinstance(value, dt.date):
        return dt.datetime.combine(value, dt.time())

    text = str(value).strip()
    # å°è¯• ISO è§£æ
    try:
        return dt.datetime.fromisoformat(text)
    except Exception:
        pass

    formats = [
        "%Y-%m-%d %H:%M:%S %z",
        "%Y-%m-%d %H:%M %z",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d %H:%M",
        "%Y-%m-%d",
    ]
    for fmt in formats:
        try:
            return dt.datetime.strptime(text, fmt)
        except Exception:
            continue
    return None


def normalize_datetime(value: dt.datetime) -> dt.datetime:
    """å°†æœ‰æ—¶åŒºçš„ datetime è½¬æ¢ä¸º UTC å†å»æ‰ tzinfoï¼Œä¾¿äºç»Ÿä¸€æ’åºã€‚"""
    if value.tzinfo:
        return value.astimezone(dt.timezone.utc).replace(tzinfo=None)
    return value


def derive_date(meta: Dict, filename: str) -> dt.datetime:
    fm_date = parse_date(meta.get("date"))
    if fm_date:
        return normalize_datetime(fm_date)

    prefix_match = re.match(r"(\d{4}-\d{2}-\d{2})", os.path.basename(filename))
    if prefix_match:
        parsed = parse_date(prefix_match.group(1))
        if parsed:
            return normalize_datetime(parsed)

    print(f"[WARN] æœªè§£æåˆ°æœ‰æ•ˆæ—¥æœŸï¼Œä½¿ç”¨é»˜è®¤ 1970-01-01: {filename}", file=sys.stderr)
    return dt.datetime(1970, 1, 1)


def extract_title(meta: Dict, filename: str) -> str:
    if meta.get("title"):
        return str(meta["title"]).strip()
    stem = os.path.splitext(os.path.basename(filename))[0]
    stem = re.sub(r"^\d{4}-\d{2}-\d{2}-", "", stem)
    return stem or filename


def detect_image_label(body: str) -> Tuple[str, List[str]]:
    sources: List[str] = []
    for pattern in IMAGE_PATTERNS:
        for match in pattern.finditer(body):
            src = match.group("src").strip()
            sources.append(src)
    if not sources:
        return "â–", []

    categories = set()
    for src in sources:
        lowered = src.lower()
        if lowered.startswith("http://") or lowered.startswith("https://"):
            categories.add("external")
        elif "images/" in lowered or "attachments/" in lowered:
            categories.add("local")
        else:
            categories.add("other")

    if categories == {"local"}:
        label = "ğŸ–¼ï¸"
    elif categories == {"external"}:
        label = "ğŸŒ"
    elif categories == {"other"}:
        label = "â“"
    else:
        label = "ğŸ”€"
    return label, sorted(categories)


def detect_type(path: str) -> str:
    normalized = path.replace("\\", "/").rstrip("/")
    if "/_posts/" in normalized or normalized.endswith("/_posts"):
        return "post"
    return "draft"


def resolve_published(meta: Dict, path: str) -> bool:
    """å¯¹ _posts ç¼ºçœè§†ä¸ºå‘å¸ƒï¼›æ˜¾å¼ published: false æ‰è§†ä¸ºæœªå‘å¸ƒã€‚è‰ç¨¿å§‹ç»ˆæœªå‘å¸ƒã€‚"""
    content_type = detect_type(path)
    if content_type == "draft":
        return False
    published_meta = meta.get("published")
    if published_meta is False:
        return False
    return True


def resolve_permalink(meta: Dict) -> Optional[str]:
    """æ„é€ å·²å‘å¸ƒ post çš„ç«™ç‚¹é“¾æ¥ï¼Œä»…åœ¨ front matter æä¾› permalink æ—¶ä½¿ç”¨ã€‚"""
    raw = meta.get("permalink")
    if not raw:
        return None
    slug = str(raw).strip()
    slug = "/" + slug.lstrip("/")
    encoded = quote(slug, safe="/%._-~")
    return SITE_BASE.rstrip("/") + encoded


def build_record(path: str) -> Record:
    with open(path, "r", encoding="utf-8") as f:
        content = f.read()

    meta, body = split_front_matter(content)
    date_value = derive_date(meta, path)
    title = extract_title(meta, path)
    published = resolve_published(meta, path)
    content_type = detect_type(path.replace("\\", "/"))
    image_label, _ = detect_image_label(body)

    has_permalink = isinstance(meta, dict) and "permalink" in meta
    permalink_url: Optional[str] = None
    if content_type == "post" and published and has_permalink:
        permalink_url = resolve_permalink(meta)

    fmt = os.path.splitext(path)[1].lstrip(".").lower()

    remark_parts: List[str] = []
    if image_label in {"ğŸŒ", "ğŸ”€"}:
        remark_parts.append("å«å¤–é“¾å›¾ç‰‡")
    if image_label == "â“":
        remark_parts.append("å›¾ç‰‡è·¯å¾„éœ€ç¡®è®¤")
    if date_value.year == 1970:
        remark_parts.append("æ—¥æœŸéœ€è¡¥å……")
    if content_type == "post" and published and not has_permalink:
        remark_parts.append("ç¼ºpermalink")

    rel_path = os.path.relpath(path, ROOT_DIR)

    return Record(
        path=path,
        rel_path=rel_path,
        date=date_value,
        year=date_value.year,
        title=title,
        published=published,
        content_type=content_type,
        image_label=image_label,
        remark="ï¼›".join(remark_parts),
        permalink_url=permalink_url,
        fmt=fmt,
    )


def group_by_year(records: Iterable[Record]) -> Dict[int, List[Record]]:
    grouped: Dict[int, List[Record]] = {}
    for rec in records:
        grouped.setdefault(rec.year, []).append(rec)
    for recs in grouped.values():
        recs.sort(key=lambda r: (r.date, r.title), reverse=True)
    return dict(sorted(grouped.items(), key=lambda item: item[0], reverse=True))


def render_markdown(grouped: Dict[int, List[Record]]) -> str:
    lines: List[str] = []
    lines.append("# å†…å®¹ç›®å½•")
    lines.append(f"- Generated at: {dt.datetime.now().isoformat(timespec='seconds')}")
    lines.append("- åŠŸèƒ½ï¼šå¿«é€Ÿæµè§ˆæ–‡ç« /è‰ç¨¿çŠ¶æ€ï¼ˆæŒ‰å¹´åˆ†ç»„ï¼Œæ—¥æœŸé™åºï¼‰")
    lines.append("- ç”Ÿæˆï¼špython scripts/generate_content_index.py")
    lines.append("")

    header = "| æ—¥æœŸ | æ ‡é¢˜ | æ˜¯å¦å‘å¸ƒ | ç±»å‹ | æœ‰å›¾ç‰‡ | æ ¼å¼ | ç›¸å¯¹è·¯å¾„ | å¤‡æ³¨ |"
    separator = "| --- | --- | --- | --- | --- | --- | --- | --- |"

    for year, recs in grouped.items():
        publish_count = sum(1 for r in recs if r.content_type == "post" and r.published)
        pending_count = sum(1 for r in recs if r.content_type == "post" and not r.published)
        draft_count = sum(1 for r in recs if r.content_type == "draft")
        lines.append(f"## {year}ï¼ˆå‘å¸ƒ: {publish_count}, å¾…å‘å¸ƒ: {pending_count}, è‰ç¨¿: {draft_count}ï¼‰")
        lines.append(header)
        lines.append(separator)
        for rec in recs:
            date_str = rec.date.strftime("%Y-%m-%d")
            safe_title = rec.title.replace("|", "\\|")
            if rec.permalink_url:
                title_md = f"[{safe_title}]({rec.permalink_url})"
            else:
                title_md = safe_title
            path_md = f"[{rec.rel_path}]({rec.rel_path})"
            published = "âœ…" if rec.published else "âŒ"
            lines.append(
                f"| {date_str} | {title_md} | {published} | {rec.content_type} | {rec.image_label} | {rec.fmt} | {path_md} | {rec.remark} |"
            )
        lines.append("")
    return "\n".join(lines).rstrip() + "\n"


def write_output(content: str) -> None:
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"[INFO] å·²ç”Ÿæˆ {OUTPUT_FILE}")


def main() -> None:
    files = list_markdown_files()
    if not files:
        print("[WARN] æœªæ‰¾åˆ° Markdown æ–‡ä»¶", file=sys.stderr)
        return

    records = [build_record(path) for path in files]
    grouped = group_by_year(records)
    markdown = render_markdown(grouped)
    write_output(markdown)


if __name__ == "__main__":
    main()
